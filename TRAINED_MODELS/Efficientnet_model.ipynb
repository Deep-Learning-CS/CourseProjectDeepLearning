{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#EFFICIENTB0 MODEL"
      ],
      "metadata": {
        "id": "8byWTe2RKC6M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1RJTCWmIIMZ",
        "outputId": "df9a6704-12f5-401a-8889-1bbfbe88d296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: speechbrain in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from speechbrain) (24.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.13.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from speechbrain) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from speechbrain) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from speechbrain) (2.5.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from speechbrain) (4.66.5)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from speechbrain) (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9->speechbrain) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain) (2.32.3)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.10/dist-packages (from hyperpyyaml->speechbrain) (0.18.6)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain) (0.2.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->speechbrain) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (2024.8.30)\n",
            "Mounted at /content/drive\n",
            "Extraction completed successfully to /content/extracted\n"
          ]
        }
      ],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import soundfile as sf\n",
        "import librosa.display\n",
        "#!pip uninstall speechbrain\n",
        "!pip install speechbrain\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dataset_path = '/content/drive/MyDrive/dev-clean.tar.gz'\n",
        "# extract the dataset\n",
        "import tarfile\n",
        "import os\n",
        "\n",
        "# Directory to save extracted files and spectrograms\n",
        "extracted_dir = '/content/extracted'\n",
        "os.makedirs(extracted_dir, exist_ok=True)\n",
        "\n",
        "# Extract the dataset\n",
        "try:\n",
        "    with tarfile.open(dataset_path, 'r:gz') as tar:\n",
        "        tar.extractall(path=extracted_dir)\n",
        "        print(f\"Extraction completed successfully to {extracted_dir}\")\n",
        "except tarfile.ReadError:\n",
        "    print(\"Error: Unable to read the tar file. It might be corrupted.\")\n",
        "except EOFError:\n",
        "    print(\"Error: The file seems to be incomplete or corrupted.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "lkb1YH-5Kccx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "IMG_SIZE = (128, 128, 3)  # EfficientNet expects 3 channels (RGB)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "# Function to load audio file, add noise, and create a Mel spectrogram\n",
        "def load_and_preprocess_audio(audio_path, sr=22050, n_mels=128, hop_length=512):\n",
        "    waveform, _ = librosa.load(audio_path, sr=sr)\n",
        "    mel_spectrogram = librosa.feature.melspectrogram(y=waveform, sr=sr, n_mels=n_mels, hop_length=hop_length)\n",
        "    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
        "    # Normalize to range [0, 1] and convert to 3 channels\n",
        "    mel_spectrogram_db = np.clip((mel_spectrogram_db + 80) / 80, 0, 1)  # Normalize between 0 and 1\n",
        "    mel_spectrogram_rgb = np.stack([mel_spectrogram_db] * 3, axis=-1)  # Convert to 3 channels\n",
        "    return mel_spectrogram_rgb\n",
        "\n"
      ],
      "metadata": {
        "id": "MhWE2N4TLHn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " Denoising autoencoder model definition with EfficientNet\n",
        "def create_denoising_autoencoder(input_shape=IMG_SIZE):\n",
        "    # Encoder using EfficientNetB0\n",
        "    base_model = tf.keras.applications.EfficientNetB0(include_top=False, weights='imagenet', input_shape=input_shape)\n",
        "    base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = base_model(inputs)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "    encoded = tf.keras.layers.Dense(32, activation='relu')(x)\n",
        "\n",
        "    # Decoder\n",
        "    x = tf.keras.layers.Dense(64, activation='relu')(encoded)\n",
        "    x = tf.keras.layers.Dense(np.prod((32, 32, 128)), activation='relu')(x)  # Adjust to output shape\n",
        "    x = tf.keras.layers.Reshape((32, 32, 128))(x)  # Reshape to 3D tensor\n",
        "\n",
        "    x = tf.keras.layers.Conv2DTranspose(128, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
        "    x = tf.keras.layers.Conv2DTranspose(64, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
        "    outputs = tf.keras.layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)  # Output layer\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "RO2FtpfFK4td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Instantiate and compile model\n",
        "autoencoder = create_denoising_autoencoder()\n",
        "autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss='mse')"
      ],
      "metadata": {
        "id": "VMJgv6CHKkVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define input and target datasets (noisy and clean Mel spectrograms)\n",
        "# Assuming noisy_mel_spectrograms and clean_mel_spectrograms are your data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((mel_spectrograms_noisy, mel_spectrograms_original))\n",
        "train_dataset = train_dataset.shuffle(1024).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Train the model\n",
        "autoencoder.fit(train_dataset, epochs=EPOCHS)\n",
        "\n",
        "\n",
        "# Save the model\n",
        "autoencoder.save('efficientnet_denoising_autoencoder.h5')"
      ],
      "metadata": {
        "id": "3Uqwbe3jJFaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DhIJA4cEJLYy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}