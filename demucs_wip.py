# -*- coding: utf-8 -*-
"""demucs_wip.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13GxbEh_mQAH50GyLkHMvAVpvqtWgSLPi

DATA EXTRACTION
"""

import librosa
import numpy as np
import matplotlib.pyplot as plt
import soundfile as sf
import librosa.display
#!pip uninstall speechbrain
!pip install speechbrain
from google.colab import drive
drive.mount('/content/drive')
dataset_path = '/content/drive/MyDrive/dev-clean.tar.gz'
# extract the dataset
import tarfile
import os

# Directory to save extracted files and spectrograms
extracted_dir = '/content/extracted'
os.makedirs(extracted_dir, exist_ok=True)

# Extract the dataset
try:
    with tarfile.open(dataset_path, 'r:gz') as tar:
        tar.extractall(path=extracted_dir)
        print(f"Extraction completed successfully to {extracted_dir}")
except tarfile.ReadError:
    print("Error: Unable to read the tar file. It might be corrupted.")
except EOFError:
    print("Error: The file seems to be incomplete or corrupted.")



"""PREPROCESSED DATA AND APPLICATION OF DEMUCS"""

import os
import numpy as np
import librosa
import matplotlib.pyplot as plt
import librosa.display

class Preprocessing:
    def load_audio(self, file_path: str) -> tuple:
        """
        Load an audio file and return its waveform and sample rate.

        Parameters:
        file_path (str): Path to the audio file.

        Returns:
        tuple: Audio waveform (np.ndarray) and sample rate (int).
        """
        audio, sr = librosa.load(file_path, sr=None)  # Load audio with original sampling rate
        return audio, sr

    def add_noise(self, audio: np.ndarray, noise_factor: float = 0.02) -> np.ndarray:
        """
        Adds random noise to an audio signal.

        Parameters:
        audio (np.ndarray): Input audio signal.
        noise_factor (float): Factor to scale the noise.

        Returns:
        np.ndarray: Noisy audio signal.
        """
        noise = np.random.randn(len(audio))
        noisy_audio = audio + noise_factor * noise

        # Clip values to ensure they remain in the valid audio range (-1 to 1)
        noisy_audio = np.clip(noisy_audio, -1.0, 1.0)

        return noisy_audio

    def extract_spectrogram(self, audio: np.ndarray, sr: int = 22050) -> np.ndarray:
        """
        Convert the audio waveform to a Mel spectrogram.

        Parameters:
        audio (np.ndarray): The audio waveform.
        sr (int): The sampling rate of the audio.

        Returns:
        np.ndarray: Spectrogram (magnitude in decibels).
        """
        # Extract Mel-spectrogram
        spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=2048, hop_length=512)

        # Convert to decibels (dB scale)
        spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)

        return spectrogram_db

    def save_spectrogram(self, spectrogram: np.ndarray, file_path: str):
        """
        Save the spectrogram as a .npy file.

        Parameters:
        spectrogram (np.ndarray): The spectrogram to save.
        file_path (str): Path where to save the spectrogram file.
        """
        np.save(file_path, spectrogram)
        print(f"Spectrogram saved at {file_path}")

    def plot_spectrogram(self, spectrogram: np.ndarray, sr: int, title: str):
        """
        Plot the spectrogram.

        Parameters:
        spectrogram (np.ndarray): The spectrogram data.
        sr (int): Sampling rate of the original audio.
        title (str): Title for the plot.
        """
        plt.figure(figsize=(10, 4))
        librosa.display.specshow(spectrogram, sr=sr, hop_length=512, x_axis='time', y_axis='mel')
        plt.colorbar(format='%+2.0f dB')
        plt.title(title)
        plt.tight_layout()
        plt.show()

#APPLYING DEMUCS FOR

    def separate_sources(self, audio_file: str, output_dir: str):
        """
        Use Demucs to perform source separation on a given audio file.
        """
        # Load the pretrained Demucs model
        model = pretrained.get_model('demucs')

        # Load the audio file using the AudioFile class from Demucs
        audio = AudioFile(audio_file)

        # Perform source separation
        with torch.no_grad():
            sources = model.separate(audio)

        # Save the separated components (e.g., vocals, drums, bass)
        sf.write(os.path.join(output_dir, f'{os.path.basename(audio_file)}_vocals.wav'), sources['vocals'], audio.samplerate)
        sf.write(os.path.join(output_dir, f'{os.path.basename(audio_file)}_drums.wav'), sources['drums'], audio.samplerate)
        sf.write(os.path.join(output_dir, f'{os.path.basename(audio_file)}_bass.wav'), sources['bass'], audio.samplerate)
        sf.write(os.path.join(output_dir, f'{os.path.basename(audio_file)}_other.wav'), sources['other'], audio.samplerate)

        print(f"Separation complete! Files saved for {audio_file}.")

# Usage Example
# Set paths
dataset_path = '/content/drive/MyDrive/dev-clean.tar.gz' # Update with your path in Google Drive
extracted_dir = '/content/extracted'
output_dir = '/content/mel_spectrograms'

# Create directories if they don't exist
os.makedirs(extracted_dir, exist_ok=True)
os.makedirs(output_dir, exist_ok=True)
# Preprocessing class instance
preprocessor = Preprocessing()

# Example for one audio file (replace with your actual audio file path)
audio_file = '/content/extracted/LibriSpeech/dev-clean/1462/170138/1462-170138-0000.flac'  # Replace with an actual path to an audio file

# Process and separate sources using Demucs
preprocessor.separate_sources(audio_file, output_dir)

"""The error encountered is :
ModelLoadingError: demucs is neither a single pre-trained model or a bag of models.
With my conversation with GPT , it gave multiple reasons for the issue:

1.version issue(I tried this  but it led to no improvement)

2.Usage of torch.hub is also not displaying any signs of feasibility.

3.installed all required dependencies

"""

#attempt 1_: tried upgrading demucs version
!pip install --upgrade demucs

#Fine-tuning the Pretrained Demucs Model
#We will fine-tune Demucs to reduce noise by training it on noisy-clean pairs.

#this code is a reference demucs code for future work.

import torch
from demucs import pretrained
from demucs.audio import AudioFile
import soundfile as sf
import os
import numpy as np
import librosa

# Load the pretrained Demucs model
model = pretrained.get_model('demucs')

# Fine-tune parameters
LEARNING_RATE = 1e-5
BATCH_SIZE = 16
EPOCHS = 10
IMG_SIZE = (128, 128, 3)

# Load noisy and clean spectrogram pairs for training
# Assuming you have paths to the noisy and clean spectrograms
def load_noisy_clean_pairs(noisy_dir, clean_dir):
    noisy_files = [os.path.join(noisy_dir, f) for f in os.listdir(noisy_dir) if f.endswith('.npy')]
    clean_files = [os.path.join(clean_dir, f) for f in os.listdir(clean_dir) if f.endswith('.npy')]
    return noisy_files, clean_files

# Train the model
def train_denoising_model(model, noisy_files, clean_files, batch_size=BATCH_SIZE, epochs=EPOCHS):
    model.train()  # Set the model to training mode
    criterion = torch.nn.MSELoss()  # Use MSE loss for denoising
    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)

    for epoch in range(epochs):
        epoch_loss = 0
        for i in range(0, len(noisy_files), batch_size):
            # Load the batch of noisy and clean spectrograms
            noisy_batch = []
            clean_batch = []
            for j in range(i, min(i + batch_size, len(noisy_files))):
                noisy = np.load(noisy_files[j])  # Load noisy spectrogram
                clean = np.load(clean_files[j])  # Load clean spectrogram
                noisy_batch.append(noisy)
                clean_batch.append(clean)

            noisy_batch = torch.tensor(np.array(noisy_batch), dtype=torch.float32)
            clean_batch = torch.tensor(np.array(clean_batch), dtype=torch.float32)

            optimizer.zero_grad()

            # Forward pass through the Demucs model (for source separation)
            output = model(noisy_batch)

            # Compute the loss
            loss = criterion(output, clean_batch)
            epoch_loss += loss.item()

            # Backpropagation
            loss.backward()
            optimizer.step()

        print(f"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(noisy_files)}")

# Directories containing noisy and clean spectrograms
noisy_dir = '/path/to/noisy_spectrograms'  # Update with the correct path
clean_dir = '/path/to/clean_spectrograms'  # Update with the correct path

# Load noisy-clean spectrogram pairs
noisy_files, clean_files = load_noisy_clean_pairs(noisy_dir, clean_dir)

# Fine-tune the Demucs model for denoising
train_denoising_model(model, noisy_files, clean_files)