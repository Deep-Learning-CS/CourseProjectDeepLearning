# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10rEFGe78ZVzSnoKHloFsRCOQw2Uioglz
"""

import tensorflow as tf
from tensorflow import keras
from keras.saving import load_model
from keras.utils import register_keras_serializable

# Need the below function to load the model
@register_keras_serializable()
def ssim_loss(y_true, y_pred):
  """
  Compute the SSIM loss between the true and predicted spectrograms.
  Parameters:
  y_true (tf.Tensor): True spectrogram.
  y_pred (tf.Tensor): Predicted spectrogram.
  """
  return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))


loaded_model = load_model('modeldev_luke.keras')

loaded_model.summary()

"""
Created on Wed Nov 27 11:55:53 2024
@author: Ayush
"""

import os
import random
import librosa
import numpy as np
import soundfile as sf
import matplotlib.pyplot as plt
import librosa.display

# Preprocessing class for handling audio files
class Preprocessing:
    def load_audio(self, file_path: str) -> np.ndarray:
        """
        Load an audio file and return its waveform as a numpy array.
        Parameters:
        file_path (str): Path to the audio file.
        Returns:
        np.ndarray: Audio waveform, and sample rate.
        """
        audio, sr = librosa.load(file_path, sr=None)  # Load audio with original sampling rate
        return audio, sr

    def extract_spectrogram(self, audio: np.ndarray, sr: int = 22050) -> np.ndarray:
        """
        Convert the audio waveform to a Mel spectrogram.
        Parameters:
        audio (np.ndarray): The audio waveform.
        sr (int): The sampling rate of the audio.
        Returns:
        np.ndarray: Spectrogram (magnitude in decibels).
        """
        spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=2048, hop_length=512)
        spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)
        return spectrogram_db

    def save_spectrogram(self, spectrogram: np.ndarray, file_path: str):
        """
        Save the spectrogram as a .npy file.
        Parameters:
        spectrogram (np.ndarray): The spectrogram to save.
        file_path (str): Path where to save the spectrogram file.
        """
        np.save(file_path, spectrogram)

    def match_length(self, audio: np.ndarray, target_length: int) -> np.ndarray:
        """
        Match the length of the audio to a target length by trimming or padding.
        Parameters:
        audio (np.ndarray): Input audio waveform.
        target_length (int): Target length for the audio.
        Returns:
        np.ndarray: Length-matched audio waveform.
        """
        if len(audio) < target_length:
            # Pad with zeros if shorter
            audio = np.pad(audio, (0, target_length - len(audio)), mode='constant')
        else:
            # Trim if longer
            audio = audio[:target_length]
        return audio

    def match_length_random(self, audio: np.ndarray, target_length: int) -> np.ndarray:
        """
        Match the length of the audio to a target length by choosing a random start point.
        Parameters:
        audio (np.ndarray): Input audio waveform.
        target_length (int): Target length for the audio.
        Returns:
        np.ndarray: Length-matched audio waveform.
        """
        if len(audio) < target_length:
            # Pad with zeros if shorter
            audio = np.pad(audio, (0, target_length - len(audio)), mode='constant')
        else:
            # select a random segment from the audio
            start = random.randint(0, len(audio) - target_length)
            audio = audio[start:start + target_length]
        return audio

# Function to get all noise files from a directory
def get_noise_files(noise_dir: str) -> list:
    """
    Retrieve all noise file paths from the specified directory.
    Parameters:
    noise_dir (str): Path to the directory containing noise files.
    Returns:
    list: List of noise file paths.
    """
    noise_files = []
    for root, _, files in os.walk(noise_dir):
        for file in files:
            if file.endswith(('.wav', '.flac')):  # Process only supported audio files
                noise_files.append(os.path.join(root, file))
    return noise_files

# Need the below function to extract spectrograms from audio in the form of an
# np.ndarray
def extract_windows(audio: np.ndarray, preprocessing: Preprocessing, sample_rate: int = 16000, window_duration: float = 1.02):
  """
  Extract windows of sample_rate * window_duration from the audio file. Extract
  spectrograms from them and return a list with all the spectrograms.
  Parameters:
  audio (np.ndarray): audio file to extract windows from.
  preprocessing (Preprocessing): Instance of preprocessing class.
  sample_rate (int): sampling rate of the audio file.
  window_duration (float): duration of the windows in seconds.
  """
  window_samples = int(sample_rate * window_duration)

  spectrograms = []

  for start in range(0, len(audio), window_samples):
      end = start + window_samples

      window = audio[start:end]

      if len(window) < window_samples:
        # pad with silence until the window is filled
        padding = window_samples - len(window)
        window = np.pad(window, (0, padding), mode='constant')

      spectrogram = preprocessing.extract_spectrogram(window, sample_rate)
      spectrograms.append(spectrogram)

  return spectrograms

# The below function if you want to use phase information for better results
def extract_windows_for_phase(audio: np.ndarray, preprocessing: Preprocessing, sample_rate: int = 16000,
                    window_duration: float = 1.02, hop_length: int = 512):
    """
    Extract overlapping windows of audio to match the frame extraction of STFT.

    Parameters:
    audio (np.ndarray): The audio file to extract windows from.
    preprocessing (Preprocessing): Instance of preprocessing class.
    sample_rate (int): Sampling rate of the audio file.
    window_duration (float): Duration of each window in seconds.
    hop_length (int): Step size between successive windows (in samples).

    Returns:
    List[np.ndarray]: A list of spectrograms for each extracted window.
    """
    window_samples = int(sample_rate * window_duration)  # Total samples in one window
    spectrograms = []

    for start in range(0, len(audio) - window_samples + 1, hop_length):
        end = start + window_samples
        window = audio[start:end]

        # Extract spectrogram for this window
        spectrogram = preprocessing.extract_spectrogram(window, sample_rate)
        spectrograms.append(spectrogram)

    # Handle the final window (pad if necessary)
    if len(audio) % hop_length != 0:
        last_window_start = len(audio) - window_samples
        last_window = audio[last_window_start:]
        if len(last_window) < window_samples:
            padding = window_samples - len(last_window)
            last_window = np.pad(last_window, (0, padding), mode='constant')
        spectrogram = preprocessing.extract_spectrogram(last_window, sample_rate)
        spectrograms.append(spectrogram)

    return spectrograms

# Need the below function to get the spectrogram in the right shape for training
# and to normalize the values
def add_single_channel_and_normalize(spectrograms: list[np.ndarray]) -> list[np.ndarray]:
  """
  Add single channel to the spectrogram [turn shape from (x, 128, 32) to
  (x, 128, 32, 1)] and normalize it.
  Parameters:
  spectrograms (list[np.ndarray]): List of spectrogram arrays.
  """
  min_val = -80
  max_val = 0

  rgb_spectrograms = np.repeat(np.array(spectrograms)[..., np.newaxis], 1, axis=-1)
  normalized_spectrograms = (rgb_spectrograms - min_val) / (max_val - min_val)

  return normalized_spectrograms

# Need the below function to inverse spectrogram into audio
def inverse_spectrogram(spectrogram: np.ndarray, volume_factor: int = 1):
  """
  Turn the spectrogram back into audio.
  Parameters:
  spectrogram (np.ndarray): The spectrogram to turn back into audio.
  volume_factor (int): The volume factor to apply to the audio.
  """
  mel_spectrogram = librosa.db_to_power(spectrogram)
  linear_spectrogram = librosa.feature.inverse.mel_to_stft(mel_spectrogram, sr=16000, n_fft=2048)
  # Feed free to experiment with n_iter -> larger values I think are more accurate,
  # but also take longer
  audio_signal = librosa.griffinlim(linear_spectrogram, n_iter=64, hop_length=512, n_fft=2048)
  audio_signal *= volume_factor
  return audio_signal

# Inverse spectrogram into audio using phase information
def inverse_spectrogram_with_phase(spectrogram: np.ndarray, phase, volume_factor: int = 1, ):
  """
  Turn the spectrogram back into audio.
  Parameters:
  spectrogram (np.ndarray): The spectrogram to turn back into audio.
  volume_factor (int): The volume factor to apply to the audio.
  """
  mel_spectrogram = librosa.db_to_power(spectrogram)
  linear_spectrogram = librosa.feature.inverse.mel_to_stft(mel_spectrogram, sr=16000, n_fft=2048)

  min_time_frames = min(linear_spectrogram.shape[1], phase.shape[1])
  linear_spectrogram = linear_spectrogram[:, :min_time_frames]
  phase = phase[:, :min_time_frames]

  reconstructed_stft = linear_spectrogram * np.exp(1j * phase)

  audio_signal = librosa.istft(reconstructed_stft, hop_length=512, n_fft=2048)
  audio_signal *= volume_factor
  return audio_signal

# Denoise audio from start to finish using no phase information
def denoise_audio(audio_file: str, model: keras.Model):
  """
  Denoise the audio file using the given model.
  Parameters:
  audio_file (str): The path to the audio file to denoise.
  model (keras.Model): The model to use for denoising.
  """
  audio, sr = librosa.load(audio_file, sr=16000)

  # Preprocess the audio file, turning it into spectrograms
  preprocessing = Preprocessing()
  extracted_spectrograms = extract_windows(audio, preprocessing, 16000, 1.02)
  normalized_spectrograms = add_single_channel_and_normalize(extracted_spectrograms)

  # Get predictions
  predictions = model.predict(normalized_spectrograms)

  min_val = -80
  max_val = 0

  # Process the predicted spetrograms back into audio
  unscaled_predictions = predictions * (max_val - min_val) + min_val
  predicted_spectrograms = np.squeeze(unscaled_predictions, axis=-1)
  combined_spectrogram = np.hstack(predicted_spectrograms)
  predicted_audio = inverse_spectrogram(combined_spectrogram)

  return predicted_audio

# Denoise audio from start to finish using phase information
def denoise_audio_with_phase(audio_file: str, model: keras.Model):
  """
  Denoise the audio file using the given model.
  Parameters:
  audio_file (str): The path to the audio file to denoise.
  model (keras.Model): The model to use for denoising.
  """
  audio, sr = librosa.load(audio_file, sr=16000)

  stft_result = librosa.stft(audio, n_fft=2048, hop_length=512)
  phase = np.angle(stft_result)
  magnitude = np.abs(stft_result)

  # Preprocess the audio file, turning it into spectrograms
  preprocessing = Preprocessing()
  extracted_spectrograms = extract_windows(audio, preprocessing, 16000, 1.02)
  normalized_spectrograms = add_single_channel_and_normalize(extracted_spectrograms)

  # Get predictions
  predictions = model.predict(normalized_spectrograms)

  min_val = -80
  max_val = 0

  # Process the predicted spetrograms back into audio
  unscaled_predictions = predictions * (max_val - min_val) + min_val
  predicted_spectrograms = np.squeeze(unscaled_predictions, axis=-1)
  combined_spectrogram = np.hstack(predicted_spectrograms)

  predicted_audio = inverse_spectrogram_with_phase(combined_spectrogram, phase)

  return predicted_audio

from IPython.display import Audio

# Original Audio
Audio('noisy_1_1188-133604-0021.flac')

# Example of denoising using phase info
denoised_audio_with_phase = denoise_audio_with_phase('noisy_1_1188-133604-0021.flac', loaded_model)

display(Audio(denoised_audio_with_phase, rate=16000))

# Example of denoising without phase info
denoised_audio = denoise_audio('noisy_1_1188-133604-0021.flac', loaded_model)

display(Audio(denoised_audio, rate=16000))